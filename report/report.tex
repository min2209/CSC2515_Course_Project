\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{enumitem}
\usepackage[numbers]{natbib}
\usepackage{listings}
\lstset{language=C++}
\pagestyle{myheadings}

\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\duedate}{December 21, 2015}

\begin{document}
\begin{titlepage}
    \begin{center}
        \vspace*{0cm}
        
        \LARGE
        CSC2515-Introduction to Machine Learning
        
        \vspace{0.5cm}
        \Huge
        \textbf{Digit Recognition in Street View House Numbers}
        
        {\Large        
        \vspace{1.0cm}
        \textbf{Bai, Min}--mbai@cs.toronto.edu\\
        \textbf{Loyzer, Mark}--loyzer@cs.toronto.edu}
        
        
        \vfill
        
        \vspace{0.5cm}
        
        \includegraphics[width=0.4\textwidth]{uoft}
        
        \Large
        Department of Computer Science\\
        University of Toronto\\
        Toronto, Ontario, Canada\\
        \duedate
        
    \end{center}
\end{titlepage}


\textbf{Abstract}\\


\title{Sections and Chapters}
\author{Min Bai, Mark Loyzer}
\date{\duedate}
\maketitle
\tableofcontents


\clearpage

\section{Abbreviations, Symbols, Nomenclature}
\begin{enumerate}
	\item[] ???
\end{enumerate}


\section{Introduction}
This project focuses on classifying digits from street view images. Towards this goal, download the Format 2 images from the Street View House numbers dataset [1] with train 32x32.mat, test 32x32.mat data, which you can find at http://ufldl.stanford.edu/housenumbers/. In this task, all the images have a fixed 32 × 32 resolution with character-level ground truth labels. For each example, the labeled character is centered at the image. There are ten classes in total 1 for each digit. Divide the training into train and validation (e.g., 80\% and 20\%).

Note that the data is collected from street-view images, thus there exist vast intra-class variations. To generate competitive performance, you may want to consider exploiting good feature representations that are robust to those variations, whether they should be hand-crafted features or learned features. In order to boost performance, you may also want to consider augmenting the training data with extra 32x32.mat. The purpose of this project is to investigate machine learning techniques to solve this task. Try things that we have seen in class, or other techniques if you feel like it. Write in your report what you have done, what you observe, what you have tried, why you did what you did, etc.

\section{Techniques}

\subsection{Convolutional Neural Networks}

\subsection{K-Nearest Neighbours}
K-Nearest Neighbours (K-NN) has traditionally performed very well in a variety of tasks so we will use K-NN with a variety of preprocessing techniques. These techniques include:

\begin{itemize}
	\item Each RGB colour channel as added features. Considering how K-NN prevails in situations where the dataset has a smooth distribution (ie. the number of dimensions can't be too large unless you have a plethora of data), we expect this to produce poor results.
	\item Each RGB colour channel as an additional example. The idea behind this technique is to expect that colours do not matter, but intensities do. Additionally we can gain three times the number of examples.
	\item Converting examples to grayscale. Similarly, if the colours do not influence the class then converting to grayscale should be an efficient way to reduce the dimensionality.
	\item Normalizing grayscale examples assuming again that intensities contain information.
	\item Normalizing grayscale examples with a threshold so that all pixels below the threshold will be 0.
	\item Extracting hard coded feature detectors ()
\end{itemize}
All techniques will be evaluated for $K \in \{1, 3, 5, 7, 9, 11, 13, 15, 17, 19\}$.

\subsubsection{RGB Channels as Features}
Figure~\ref{fig:knn_rgb_features} shows the accuracy of using KNN to classify SVHN. The accuracies range from __\% to __\%; however, all are very low due to not having a smooth distribution as each example will have $32 x 32 x 3 = 3072$ dimensions.
\begin{figure}
	\includegraphics[width=\textwidth]{./plots/knn_rgb_features}
    	\caption{Performance of K-NN using images' RGB channels as features}
	\label{fig:knn_rgb_features}
\end{figure}

\subsubsection{RGB Channels as Added Examples}
Figure~\ref{fig:knn_rgb_examples} shows the accuracy of using KNN to classify SVHN
\begin{figure}
	\includegraphics[width=\textwidth]{./plots/knn_rgb_examples}
    	\caption{Performance of K-NN using images' RGB channels as added examples}
	\label{fig:knn_rgb_examples}
\end{figure}


\subsubsection{Concluding Remarks}


\section{Conclusion}


\section{References}
\nocite{*}
\bibliographystyle{plainnat}
\bibliography{research}
\end{document}